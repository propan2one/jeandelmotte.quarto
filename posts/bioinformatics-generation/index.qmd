---
title: "The different generation of bioinformatics analysis"
author: "Jean DELMOTTE"
date: "2024-11-21"
categories: [Opinion, Bioinformatics, Workflow managers]
---

::: columns

::: {.column width="30%"}

![](IA_postprod_image.jpg)
:::

::: {.column width="10%"}

:::

::: {.column width="60%"}
Today, the volume of data to be analysed in bioinformatics is such that it's essential to use a number of tools to produce results in a consistent timeframe. However, these advances are not always used, so let's take a look back at the history of analysis methods over the last 10 years.
:::

:::

To fully understand what these modalities refer to, I need to introduce you to the notion that I call the different **generations**, often speaking of the generation I, II or III pipeline (abbreviated as GI, GII etc..). Of course, defined limits are not so clearly defined, and often generations of tools coexist within a lab or organization. I'll now describe what I consider to be the different generations, and then conclude by explaining the advantages of such a category. If you're a bioinformatician, you can go straight to the GII pipeline.


### Generation I pipelines

Funnily enough, these different generations can be found throughout a bioinformatician's career. Because I've been doing bioinfo for 7 years I started my journey by using Graphical tools. There are many solutions for processing data using a grapichal user interface, such as [Ugene](https://ugene.net/) a free open-source bioinformatics software, [Geneious prime](https://www.geneious.com/features/prime), [CLC genomics workbench](https://digitalinsights.qiagen.com/products-overview/discovery-insights-portfolio/analysis-and-visualization/qiagen-clc-genomics-workbench/) or even [snapgene](https://www.snapgene.com/).

The advantage of this software is that it allows you to quickly understand the data you're working with. This is very important for genomic analyses, for example, where data can be easily trimmed, mapped against a reference or even perform *de novo* assembly. The visualizations of data or results they provide are very interesting. However, for some of them, the algorithms used are black boxes such as trimming or variant calling in CLC. So the main risk, which is also their strength, is that they try to summarize complex parameters in simple values. This type of approach may be sufficient as long as complex cases are not encountered, and pharmaceutical companies love simple answers. Another concern for users is the manual, sequential (one sample at a time) set-up of the analysis. Some software packages allow batch analysis, which is good but not efficient.

Together, *Generation I* (GI) tools/pipelines are sufficient for small datasets, often for use by biologists. They are used routinely, with a very simple workflow. Bioinformaticians employing them can use them to visualize data or decrease the workload by training biologists. Sometimes by coding a small part on the side (merging VCFs etc.).

### Generation II pipelines

::: columns

::: {.column width="65%"}

What I call *Generation II* (GII) pipelines are everything that comes close to bash-coded pipelines. When coupled with a launch interface and an academic or cloud server, it allows you to run all available bioinfo tools. We're not going to lie, we've all done it, it's ugly, but it works and sometimes it allows you to go fast (for a POC or whatever). Sometimes it's an analysis in Python or R, but the idea remains the same: it's a script (often monolithic) that chains together the analysis tools. You'll often find conda environment calls directly in the code or singularity image to manage the bioinformatics sofware. Most of the time, it's the bioinformatician who developed it who launches it for his analyses, but sometimes with the use of an app (a feature of GIII) allows the pipeline to be transmitted to several users, including biologists. Here the constraint is to provide the user with a consistent interface (asking the user to modify a YAML can sometimes be problematic for the user).

:::

::: {.column width="5%"}

:::

::: {.column width="30%"}
![One script to rule them all](GII_pipeline_example.png)
:::

:::

Through these GII pipelines, bioinformaticians are free to use all the tools developed by the community or themselves, the only limit being computing power. Then, in the case of a large number of samples, a loop to launch the command line parsing a TSV file retrieving the raw data will do the trick (which is built using good old `ls` of course). All this is feasible and, depending on the need, it's not a bad thing. After all, it's the same manual analysis we do on our servers. I know of production pipelines that are still running with this several years after the last commit, and they're reliable! Just to mention it, using [Galaxy](https://usegalaxy.org/) is a bit of a hybrid between GI & GII, as it provides a wide range of up-to-date tools via its community, the possibility of assembling them into DAGs and automating complex analyses.

The limitation of these generation two pipelines is that *i)* since the analyses are sequential, the computational cost is proportional to the number of samples. *ii)* Often it's a combination of generation II pipeline to make end to end analysis. For example, a pipeline run 'n' times to assemble 'n' genomes, and another pipeline to compare these 'n' genomes. *iii)* Working with several people on these tools can quickly become a nightmare.

### Generation III

That's where Generation III pipelines come in by using the **W**orkflow **M**anagement **S**ystems (**WfMS**) ([Ahmed et al. 2021](10.1038/s41598-021-99288-8)). From my point of view, it's literally a **language for parallelizing task**. In the case of bioinformatics analysis it's very powerful because you sahre the computing power between samples and process, can trigger several comportement for autoscaling pipeline and more. You're probably familiar with WfMS languages such as [Snakemake](https://snakemake.readthedocs.io/en/stable/), [Nextflow](https://www.nextflow.io/docs/latest/index.html), [CWL](https://www.commonwl.org/), [Airflow](https://airflow.apache.org/) and [WDL](https://openwdl.org/) etc.. 


When coupled with a launch interface ([ShinyApp](https://www.shinyapps.io/), [Streamlit](https://streamlit.io/) or even better an [EPAM Cloud Pipeline](https://lifescience.opensource.epam.com/cloud/) infra) and an academic or cloud server, it allows you to run all available bioinfo tools.

<script style="text-align:center" type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="propan2one" data-color="#3b0579" data-emoji="" data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#ffffff" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script>
